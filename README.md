# ğŸ“¸ Face Tracker  

## ğŸ“ Description  
This repository contains a face-tracking application that captures facial images, trains a model using the **VGG16** architecture, and tests face detection in real-time.  

## ğŸ“¦ Requirements  

Ensure you have the following installed:  

- Python **3.x**  
- Jupyter Notebook  
- TensorFlow  
- OpenCV  
- Albumentations  
- Labelme  

You can install all required packages using:  
```bash
pip install tensorflow opencv-python albumentations labelme
```

## ğŸ”§ How to Use the Application  

### **1ï¸âƒ£ Download the Repository**  
Clone or download the repository to your local machine:  
```bash
git clone <repository_link>
cd <repository_directory>
```

### **2ï¸âƒ£ Prepare the Data Folders**  
Before starting, delete all the photos and labels in the `data` and `aug_data` folders to ensure a fresh start.  

### **3ï¸âƒ£ Capture Facial Images**  
Run the following command to start capturing facial images using your webcam:  
```bash
jupyter notebook data.ipynb
```
- This will prompt the webcam to capture photos of your face.

### **4ï¸âƒ£ Annotate the Images**  
Use `labelme` to annotate the images by following these steps:  

#### **Start the Annotation Tool**  
Run the command:  
```bash
labelme
```
This will open the Labelme interface.  

#### **Load the Images**  
- Navigate to the `data/images/` folder where your captured images are stored.  
- Click **File** â†’ **Change Output Directory** and select `data/labels/`.  
- Click **File** â†’ **Save Automatically** to ensure annotations are saved automatically.  

#### **Annotate Each Image**  
- Click **Edit** â†’ **Create Rectangle** to start drawing bounding boxes.  
- Manually draw a box around your face for each image.  
- When prompted, enter the class name (e.g., `"face"`) and click **OK**.  

#### **Navigating Through Images**  
- Press `D` on your keyboard to move to the next image.  
- If an image **does not contain a face**, **skip it** without annotating.  

Once completed, `labelme` will generate JSON files in `data/labels/`, containing the bounding box coordinates and class labels.  

### **5ï¸âƒ£ Train the Model**  
Start the model training process by running:  
```bash
jupyter notebook model.ipynb
```
- Images and labels will be sorted into `train`, `test`, and `val` folders.  
- Augmentation will be applied using **Albumentations**, with the augmented images stored in `aug_data/{train,test,val}/images` and their corresponding labels saved in `aug_data/{train,test,val}/labels`.
- After training, the model will be saved as `facetracker_vgg16.h5` in your **Desktop directory**.  

### **6ï¸âƒ£ Test the Face Detection App**  
To test face detection using the trained model, run:  
```bash
jupyter notebook model_test.ipynb
```
- This will allow you to validate the face-tracking functionality in real time.

  ![Demo](test.gif)

  ![Demo](test-speed.gif)

---

## ğŸ“‚ Folder Structure  
```plaintext
â”œâ”€â”€ aug_data/         # Augmented images generated using Albumentations  
â”‚   â”œâ”€â”€ train/       # Augmented training data  
â”‚   â”‚   â”œâ”€â”€ images/   # Augmented training images  
â”‚   â”‚   â”œâ”€â”€ labels/   # Corresponding JSON labels  
â”‚   â”œâ”€â”€ test/        # Augmented test data  
â”‚   â”‚   â”œâ”€â”€ images/   # Augmented test images  
â”‚   â”‚   â”œâ”€â”€ labels/   # Corresponding JSON labels  
â”‚   â”œâ”€â”€ val/         # Augmented validation data  
â”‚   â”‚   â”œâ”€â”€ images/   # Augmented validation images  
â”‚   â”‚   â”œâ”€â”€ labels/   # Corresponding JSON labels  
â”œâ”€â”€ data/            # Raw captured images and annotations
â”‚   â”œâ”€â”€ images       # Original directory containing the images before the train-test-val split
â”‚   â”œâ”€â”€ labels       # Original directory containing the labels before the train-test-val split
â”‚   â”œâ”€â”€ train/       # Training data  
â”‚   â”‚   â”œâ”€â”€ images/   # Raw training images  
â”‚   â”‚   â”œâ”€â”€ labels/   # JSON annotations from Labelme  
â”‚   â”œâ”€â”€ test/        # Test data  
â”‚   â”‚   â”œâ”€â”€ images/   # Raw test images  
â”‚   â”‚   â”œâ”€â”€ labels/   # JSON annotations from Labelme  
â”‚   â”œâ”€â”€ val/         # Validation data  
â”‚   â”‚   â”œâ”€â”€ images/   # Raw validation images  
â”‚   â”‚   â”œâ”€â”€ labels/   # JSON annotations from Labelme  
â”œâ”€â”€ logs/            # Stores callback logs during model training  
â”œâ”€â”€ data.ipynb       # Captures facial images and generates labels  
â”œâ”€â”€ model.ipynb      # Trains the VGG16-based face tracking model  
â”œâ”€â”€ model_test.ipynb # Tests the trained model for face detection  
â”œâ”€â”€ README.md        # Project documentation  
â”œâ”€â”€ .DS_Store        # macOS system file (safe to ignore)  


---

## ğŸ’¡ Contributing  
Feel free to contribute by submitting **issues** or **pull requests**! ğŸ˜Š  

